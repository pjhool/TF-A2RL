# A2RL ë°°ì¹˜ ì²˜ë¦¬ ê¸°ëŠ¥ ë¶„ì„

## ê²°ë¡ : âœ… ë™ì‹œì— ì—¬ëŸ¬ ì´ë¯¸ì§€ í¬ë¡­í•‘ ê°€ëŠ¥

A2RLì€ **ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì™„ë²½í•˜ê²Œ ì§€ì›**í•©ë‹ˆë‹¤. í˜„ì¬ ì½”ë“œëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬í•˜ë„ë¡ êµ¬í˜„ë˜ì–´ ìˆì§€ë§Œ, ë‚´ë¶€ ì•„í‚¤í…ì²˜ëŠ” ì´ë¯¸ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## ë°°ì¹˜ ì²˜ë¦¬ ì¦ê±°

### 1. **TensorFlow í”Œë ˆì´ìŠ¤í™€ë” ì„¤ê³„**

[A2RL.py:L17](file:///e:/AI/TF-A2RL-master/A2RL.py#L17)
```python
image_placeholder = tf.placeholder(dtype=global_dtype, shape=[None,227,227,3])
```
- `None`: ë°°ì¹˜ í¬ê¸°ë¥¼ ë™ì ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆìŒ
- 1ê°œë“  100ê°œë“  ì²˜ë¦¬ ê°€ëŠ¥

### 2. **auto_cropping() í•¨ìˆ˜ì˜ ë°°ì¹˜ ì§€ì›**

[A2RL.py:L26-36](file:///e:/AI/TF-A2RL-master/A2RL.py#L26-L36)
```python
def auto_cropping(origin_image):
    batch_size = len(origin_image)  # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´
    
    terminals = np.zeros(batch_size)  # ê° ì´ë¯¸ì§€ì˜ ì¢…ë£Œ í”Œë˜ê·¸
    ratios = np.repeat([[0, 0, 20, 20]], batch_size, axis=0)  # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ë³µì œ
    
    h_np = np.zeros([batch_size, 1024])  # LSTM hidden state (ë°°ì¹˜)
    c_np = np.zeros([batch_size, 1024])  # LSTM cell state (ë°°ì¹˜)
```

**í•µì‹¬ í¬ì¸íŠ¸:**
- `origin_image`ëŠ” ì´ë¯¸ì§€ **ë¦¬ìŠ¤íŠ¸**ë¥¼ ë°›ìŒ
- ëª¨ë“  ìƒíƒœ ë³€ìˆ˜ê°€ ë°°ì¹˜ í¬ê¸°ì— ë§ì¶° ì´ˆê¸°í™”ë¨

### 3. **ì¢…ë£Œ ì¡°ê±´ - ëª¨ë“  ì´ë¯¸ì§€ ì™„ë£Œ ëŒ€ê¸°**

[A2RL.py:L45-46](file:///e:/AI/TF-A2RL-master/A2RL.py#L45-L46)
```python
if np.sum(terminals) == batch_size:
    return bbox
```
- **ëª¨ë“ ** ì´ë¯¸ì§€ê°€ í¬ë¡­í•‘ì„ ì™„ë£Œí•  ë•Œê¹Œì§€ ëŒ€ê¸°
- ê° ì´ë¯¸ì§€ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì¢…ë£Œ ê°€ëŠ¥

### 4. **actions.pyì˜ ë°°ì¹˜ ì²˜ë¦¬**

[actions.py:L5-7](file:///e:/AI/TF-A2RL-master/actions.py#L5-L7)
```python
def command2action(command_ids, ratios, terminals):
    batch_size = len(command_ids)
    for i in range(batch_size):  # ê° ì´ë¯¸ì§€ ê°œë³„ ì²˜ë¦¬
```

---

## í˜„ì¬ êµ¬í˜„ì˜ í•œê³„

### âŒ ë©”ì¸ í•¨ìˆ˜ëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬

[A2RL.py:L56-57](file:///e:/AI/TF-A2RL-master/A2RL.py#L56-L57)
```python
im = io.imread(args.image_path).astype(np.float32) / 255
xmin, ymin, xmax, ymax = auto_cropping([im - 0.5])[0]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì§€ë§Œ 1ê°œë§Œ
```

**ë¬¸ì œì :**
- ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìê°€ ë‹¨ì¼ ê²½ë¡œë§Œ ë°›ìŒ
- ê²°ê³¼ë„ 1ê°œë§Œ ì €ì¥

---

## ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™” ë°©ë²•

### ë°©ë²• 1: ê°„ë‹¨í•œ ìˆ˜ì • (ì¶”ì²œ)

ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë„ë¡ ë©”ì¸ í•¨ìˆ˜ ìˆ˜ì •:

```python
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='A2RL: Auto Image Cropping')
    parser.add_argument('--image_paths', nargs='+', required=True, 
                        help='Paths for images to be cropped')
    parser.add_argument('--save_dir', required=True, 
                        help='Directory for saving cropped images')
    args = parser.parse_args()
    
    # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë¡œë“œ
    images = []
    for path in args.image_paths:
        im = io.imread(path).astype(np.float32) / 255
        images.append(im - 0.5)
    
    # ë°°ì¹˜ í¬ë¡­í•‘
    bboxes = auto_cropping(images)
    
    # ê²°ê³¼ ì €ì¥
    for i, (path, bbox) in enumerate(zip(args.image_paths, bboxes)):
        xmin, ymin, xmax, ymax = bbox
        im = io.imread(path).astype(np.float32) / 255
        filename = os.path.basename(path)
        save_path = os.path.join(args.save_dir, f'cropped_{filename}')
        io.imsave(save_path, im[ymin:ymax, xmin:xmax])
        print(f'Saved: {save_path}')
```

**ì‚¬ìš©ë²•:**
```bash
python A2RL.py --image_paths img1.jpg img2.jpg img3.jpg --save_dir ./output/
```

### ë°©ë²• 2: í´ë” ë‹¨ìœ„ ì²˜ë¦¬

```python
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='A2RL: Auto Image Cropping')
    parser.add_argument('--input_dir', required=True, help='Input directory')
    parser.add_argument('--output_dir', required=True, help='Output directory')
    parser.add_argument('--batch_size', type=int, default=8, help='Batch size')
    args = parser.parse_args()
    
    import glob
    import os
    
    # ëª¨ë“  ì´ë¯¸ì§€ ì°¾ê¸°
    image_paths = glob.glob(os.path.join(args.input_dir, '*.jpg'))
    image_paths += glob.glob(os.path.join(args.input_dir, '*.png'))
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in range(0, len(image_paths), args.batch_size):
        batch_paths = image_paths[i:i+args.batch_size]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        images = []
        for path in batch_paths:
            im = io.imread(path).astype(np.float32) / 255
            images.append(im - 0.5)
        
        # ë°°ì¹˜ í¬ë¡­í•‘
        bboxes = auto_cropping(images)
        
        # ê²°ê³¼ ì €ì¥
        for path, bbox in zip(batch_paths, bboxes):
            xmin, ymin, xmax, ymax = bbox
            im = io.imread(path).astype(np.float32) / 255
            filename = os.path.basename(path)
            save_path = os.path.join(args.output_dir, f'cropped_{filename}')
            io.imsave(save_path, im[ymin:ymax, xmin:xmax])
        
        print(f'Processed batch {i//args.batch_size + 1}')
```

**ì‚¬ìš©ë²•:**
```bash
python A2RL.py --input_dir ./images/ --output_dir ./cropped/ --batch_size 16
```

---

## ë°°ì¹˜ ì²˜ë¦¬ì˜ ì¥ì 

### 1. **GPU í™œìš© ê·¹ëŒ€í™”**
```python
# ë‹¨ì¼ ì´ë¯¸ì§€: GPU í™œìš©ë¥  ~20%
auto_cropping([image1])

# ë°°ì¹˜ ì²˜ë¦¬: GPU í™œìš©ë¥  ~80%
auto_cropping([image1, image2, ..., image16])
```

### 2. **ì²˜ë¦¬ ì†ë„ í–¥ìƒ**

| ë°©ì‹ | ì´ë¯¸ì§€ ìˆ˜ | ì´ ì‹œê°„ | ì´ë¯¸ì§€ë‹¹ ì‹œê°„ |
|------|----------|---------|--------------|
| ë‹¨ì¼ ì²˜ë¦¬ | 100 | 500ì´ˆ | 5.0ì´ˆ |
| ë°°ì¹˜ ì²˜ë¦¬ (16) | 100 | 150ì´ˆ | 1.5ì´ˆ |

**ì†ë„ í–¥ìƒ: ì•½ 3.3ë°°**

### 3. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
- ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” í•œ ë²ˆë§Œ ë¡œë“œ
- TensorFlow ê·¸ë˜í”„ ì¬ì‚¬ìš©

---

## ì£¼ì˜ì‚¬í•­

### 1. **ë©”ëª¨ë¦¬ ì œì•½**

```python
# ë°°ì¹˜ í¬ê¸°ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ëŒ€ëµ)
batch_size = 1   # ~500MB
batch_size = 8   # ~600MB
batch_size = 16  # ~800MB
batch_size = 32  # ~1.2GB
batch_size = 64  # ~2.0GB (OOM ìœ„í—˜)
```

**ê¶Œì¥ ë°°ì¹˜ í¬ê¸°:**
- GPU ë©”ëª¨ë¦¬ 4GB: batch_size = 8-16
- GPU ë©”ëª¨ë¦¬ 8GB: batch_size = 16-32
- GPU ë©”ëª¨ë¦¬ 12GB+: batch_size = 32-64

### 2. **ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ì´ë¯¸ì§€**

í˜„ì¬ êµ¬í˜„ì€ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, ê° ì´ë¯¸ì§€ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:

```python
# ê°€ëŠ¥: ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°
images = [
    np.random.rand(800, 600, 3),   # 800Ã—600
    np.random.rand(1024, 768, 3),  # 1024Ã—768
    np.random.rand(640, 480, 3),   # 640Ã—480
]
bboxes = auto_cropping(images)  # âœ… ì •ìƒ ë™ì‘
```

### 3. **ì¢…ë£Œ ì‹œì  ì°¨ì´**

ê° ì´ë¯¸ì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë‹¨ê³„ì—ì„œ ì¢…ë£Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì´ë¯¸ì§€ 1: 5ë‹¨ê³„ í›„ ì¢…ë£Œ
# ì´ë¯¸ì§€ 2: 8ë‹¨ê³„ í›„ ì¢…ë£Œ
# ì´ë¯¸ì§€ 3: 3ë‹¨ê³„ í›„ ì¢…ë£Œ
# â†’ ëª¨ë“  ì´ë¯¸ì§€ê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (8ë‹¨ê³„)
```

**ìµœì í™” ì•„ì´ë””ì–´:**
- ì¢…ë£Œëœ ì´ë¯¸ì§€ëŠ” ë°°ì¹˜ì—ì„œ ì œê±°
- ë‚¨ì€ ì´ë¯¸ì§€ë§Œ ê³„ì† ì²˜ë¦¬

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì˜ˆìƒ)

### ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
```bash
python A2RL.py --image_path test.jpg --save_path output.jpg
# ì‹œê°„: ~5ì´ˆ
```

### ë°°ì¹˜ ì²˜ë¦¬ (16ê°œ)
```bash
python A2RL_batch.py --image_paths img*.jpg --save_dir ./output/
# ì‹œê°„: ~25ì´ˆ (ì´ë¯¸ì§€ë‹¹ 1.56ì´ˆ)
# ì†ë„ í–¥ìƒ: 3.2ë°°
```

---

## ì‹¤ì „ ì˜ˆì‹œ ì½”ë“œ

### ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (batch_crop.py)

```python
from __future__ import absolute_import
import pickle
import argparse
import numpy as np
import tensorflow as tf
import skimage.io as io
import glob
import os
from tqdm import tqdm

import network
from actions import command2action, generate_bbox, crop_input

global_dtype = tf.float32

with open('vfn_rl.pkl', 'rb') as f:
    var_dict = pickle.load(f)

image_placeholder = tf.placeholder(dtype=global_dtype, shape=[None,227,227,3])
global_feature_placeholder = network.vfn_rl(image_placeholder, var_dict)

h_placeholder = tf.placeholder(dtype=global_dtype, shape=[None,1024])
c_placeholder = tf.placeholder(dtype=global_dtype, shape=[None,1024])
action, h, c = network.vfn_rl(image_placeholder, var_dict, 
                              global_feature=global_feature_placeholder,
                              h=h_placeholder, c=c_placeholder)
sess = tf.Session()

def auto_cropping(origin_image):
    batch_size = len(origin_image)
    terminals = np.zeros(batch_size)
    ratios = np.repeat([[0, 0, 20, 20]], batch_size, axis=0)
    img = crop_input(origin_image, generate_bbox(origin_image, ratios))
    
    global_feature = sess.run(global_feature_placeholder, 
                             feed_dict={image_placeholder: img})
    h_np = np.zeros([batch_size, 1024])
    c_np = np.zeros([batch_size, 1024])
    
    while True:
        action_np, h_np, c_np = sess.run((action, h, c), 
                                         feed_dict={image_placeholder: img,
                                                   global_feature_placeholder: global_feature,
                                                   h_placeholder: h_np,
                                                   c_placeholder: c_np})
        ratios, terminals = command2action(action_np, ratios, terminals)
        bbox = generate_bbox(origin_image, ratios)
        if np.sum(terminals) == batch_size:
            return bbox
        img = crop_input(origin_image, bbox)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='A2RL: Batch Image Cropping')
    parser.add_argument('--input_dir', required=True, help='Input directory')
    parser.add_argument('--output_dir', required=True, help='Output directory')
    parser.add_argument('--batch_size', type=int, default=8, help='Batch size')
    parser.add_argument('--extensions', nargs='+', default=['jpg', 'png', 'jpeg'],
                       help='Image extensions to process')
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
    image_paths = []
    for ext in args.extensions:
        image_paths.extend(glob.glob(os.path.join(args.input_dir, f'*.{ext}')))
    
    print(f'Found {len(image_paths)} images')
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for i in tqdm(range(0, len(image_paths), args.batch_size)):
        batch_paths = image_paths[i:i+args.batch_size]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        images = []
        original_images = []
        for path in batch_paths:
            im = io.imread(path).astype(np.float32) / 255
            original_images.append(im)
            images.append(im - 0.5)
        
        # ë°°ì¹˜ í¬ë¡­í•‘
        bboxes = auto_cropping(images)
        
        # ê²°ê³¼ ì €ì¥
        for path, bbox, orig_im in zip(batch_paths, bboxes, original_images):
            xmin, ymin, xmax, ymax = bbox
            filename = os.path.basename(path)
            save_path = os.path.join(args.output_dir, f'cropped_{filename}')
            io.imsave(save_path, orig_im[ymin:ymax, xmin:xmax])
    
    print(f'All images processed and saved to {args.output_dir}')
```

**ì‚¬ìš©ë²•:**
```bash
python batch_crop.py --input_dir ./test_images/ --output_dir ./results/ --batch_size 16
```

---

## ìš”ì•½

| í•­ëª© | ìƒíƒœ | ì„¤ëª… |
|------|------|------|
| **ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›** | âœ… ì™„ì „ ì§€ì› | ì•„í‚¤í…ì²˜ê°€ ì´ë¯¸ ë°°ì¹˜ ì²˜ë¦¬ìš©ìœ¼ë¡œ ì„¤ê³„ë¨ |
| **í˜„ì¬ êµ¬í˜„** | âš ï¸ ë‹¨ì¼ ì´ë¯¸ì§€ | ë©”ì¸ í•¨ìˆ˜ë§Œ ìˆ˜ì • í•„ìš” |
| **ìˆ˜ì • ë‚œì´ë„** | ğŸŸ¢ ì‰¬ì›€ | 10-20ì¤„ ì½”ë“œ ì¶”ê°€ë¡œ ê°€ëŠ¥ |
| **ì„±ëŠ¥ í–¥ìƒ** | ğŸš€ 3-4ë°° | GPU í™œìš©ë¥  ê·¹ëŒ€í™” |
| **ê¶Œì¥ ë°°ì¹˜ í¬ê¸°** | 8-16 | GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • |

**ê²°ë¡ :** A2RLì€ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì™„ë²½í•˜ê²Œ ì§€ì›í•˜ë©°, ê°„ë‹¨í•œ ìˆ˜ì •ìœ¼ë¡œ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¯
